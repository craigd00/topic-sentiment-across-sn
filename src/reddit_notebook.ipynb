{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Runs Reddit API to collect posts containing a search term, and returns post with comments on it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the Reddit credentials and modules required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from redditcredentials import CLIENT_ID, CLIENT_SECRET, USERNAME_REDDIT, PASSWORD_REDDIT\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup the request for Reddit API, OAuth authentication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authorisation code from https://towardsdatascience.com/how-to-use-the-reddit-api-in-python-5e05ddfd1e5c, as tried what API github suggested and did not work\n",
    "auth = requests.auth.HTTPBasicAuth(CLIENT_ID, CLIENT_SECRET)\n",
    "\n",
    "data = {'grant_type': 'password',\n",
    "        'username': USERNAME_REDDIT,\n",
    "        'password': PASSWORD_REDDIT}\n",
    "\n",
    "headers = {'User-Agent': 'TopicSentimentAcrossSN/0.0.1'}\n",
    "\n",
    "res = requests.post('https://www.reddit.com/api/v1/access_token',\n",
    "                    auth=auth, data=data, headers=headers)\n",
    "\n",
    "TOKEN = res.json()['access_token']\n",
    "\n",
    "headers = {**headers, **{'Authorization': f\"bearer {TOKEN}\"}}\n",
    "requests.get('https://oauth.reddit.com/api/v1/me', headers=headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set search term and create the dictionary to hold posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_term = 'Scotrail'\n",
    "reddit_posts = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to get the comments from the posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCommentsFromPosts(post_id, post_title):\n",
    "        comment_results = requests.get(\"https://oauth.reddit.com/r/all/comments/\" + str(post_id),\n",
    "                                headers=headers, params={'limit': '25'})\n",
    "\n",
    "        print(\"PRINTING COMMENT RESULTS FOR THE TOPIC: \\n\")\n",
    "\n",
    "        comments = comment_results.json()[1]['data']['children'][:-1]   #slices last value as it is just list of id's\n",
    "        all_comments = []\n",
    "\n",
    "        for comment in comments:\n",
    "                comment_text = comment['data']['body']\n",
    "                all_comments += [comment_text]\n",
    "        \n",
    "        reddit_posts[post_title] = all_comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find results on search term from reddit posts, and collect comments containing that topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = requests.get(\"https://oauth.reddit.com/r/all/search\", \n",
    "                headers=headers, params={'limit': '25', 'q':{search_term}})\n",
    "\n",
    "print(\"PRINTING SEARCH RESULTS FOR THE TOPIC: \\n\")\n",
    "\n",
    "posts = results.json()['data']['children']\n",
    "\n",
    "for post in posts:\n",
    "        post_title = post['data']['title']\n",
    "        print(post_title)\n",
    "        post_id = post['data']['id']\n",
    "        getCommentsFromPosts(post_id, post_title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dictionary results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(reddit_posts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VADER Analysis test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install vaderSentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_results = []\n",
    "for post in reddit_posts.values():\n",
    "   # print(post)\n",
    "    reddit_results.extend(post)\n",
    "\n",
    "print(reddit_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "# Example code:\n",
    "\n",
    "f = open(\"reddit_scores.txt\", \"x\", encoding=\"utf-8\")\n",
    "\n",
    "for reddit_post in reddit_results:\n",
    "  vs = analyzer.polarity_scores(reddit_post)\n",
    "  compound = vs['compound']\n",
    "  sentiment_score = compound * 100\n",
    "  print(\"The post '\" + reddit_post + \"' has a sentiment score of: \" + (str(sentiment_score)) + \"%\")\n",
    "  \n",
    "  if (compound >= 0.05):\n",
    "    print(\"The post was POSITIVE\")\n",
    "    f.write(\"\\n\" + reddit_post + \": RESULT = POSITIVE\")\n",
    "  elif (compound <= -0.05):\n",
    "    print(\"The post was NEGATIVE\")\n",
    "    f.write(\"\\n\" + reddit_post + \": RESULT = NEGATIVE\")\n",
    "  else:\n",
    "    print(\"The post was NEUTRAL\")\n",
    "    f.write(\"\\n\" + reddit_post + \": RESULT = NEUTRAL\")\n",
    "  print(\"{:-<65} {}\".format(reddit_post, str(vs)))\n",
    "\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "81845dbb79d117afed2f128a4bda775071ee668bf9e9d02bb4620ddcda801259"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit ('jup_env': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
